{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from numpy import random\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "# Load the MNIST digit data\n",
    "M = loadmat(\"mnist_all.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    return exp(y) / tile(sum(exp(y), 0), (len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(y, p):\n",
    "    return -np.sum(y * np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part2(x, W0, b0):\n",
    "    #this implementations concatenates the bias vector and the weights , and then outputs the result of dimension (10, 1)\n",
    "    total_W0 = np.concatenate((b0, W0))\n",
    "    added_ones = np.ones(x.shape[1]).reshape(x.shape[1], 1)\n",
    "    total_x = np.concatenate(( added_ones.T, x))\n",
    "    vals = softmax(np.dot(total_W0.T, total_x))\n",
    "    #print(\"VAls\", vals.T)\n",
    "    return vals.T\n",
    "\n",
    "def part3(x, y1, p):\n",
    "    deriv = np.subtract(p, y1)\n",
    "    added_ones = np.ones(x.shape[1]).reshape(x.shape[1], 1)\n",
    "    total_x = np.concatenate((added_ones.T, x))\n",
    "    deriv = np.matmul(deriv, total_x.T).T\n",
    "    #print(\"Deriv.shape\", deriv.shape)\n",
    "    return deriv  # shape 785, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10075571  0.10069217  0.09993024  0.10034966  0.10033376  0.09952008\n",
      "   0.09930657  0.09971107  0.09966919  0.09973154]]\n",
      "LOG -2.30739585857\n",
      "Cost 2.30739585857\n",
      "Finite Diff -0.000844740832395\n",
      "Real Diff -0.000844740871903\n",
      "Finite Diff -0.00109400860415\n",
      "Real Diff -0.00109400867017\n",
      "Finite Diff -0.00109400860415\n",
      "Real Diff -0.00109400867017\n",
      "Finite Diff -0.00202183858233\n",
      "Real Diff -0.00202183880816\n",
      "Finite Diff -0.00242343660295\n",
      "Real Diff -0.00242343692759\n"
     ]
    }
   ],
   "source": [
    "# PART ONE DATA SNIPPIT\n",
    "snapshot = pickle.load(open(\"snapshot50.pkl\", \"rb\"), encoding=\"latin-1\")\n",
    "W0 = snapshot[\"W0\"]  # data\n",
    "b0 = snapshot[\"b0\"].reshape((300, 1))  # bias?\n",
    "W1 = snapshot[\"W1\"]  # should be likelihoods?\n",
    "b1 = snapshot[\"b1\"].reshape((10, 1))  # classes?\n",
    "#print(W0.shape)\n",
    "\n",
    "np.random.seed(0)\n",
    "weights = np.random.random(size=784*10).reshape((784, 10))\n",
    "weights_bias = np.zeros(10).reshape(1, 10)\n",
    "#np.random.random(size=10).reshape((1, 10))\n",
    "\n",
    "# PART TWO - SINGLE LAYER NN\n",
    "x = M[\"train5\"][148:149].T / 255./ 255.\n",
    "output = part2(x, weights, weights_bias)\n",
    "output = output.reshape(10,1)\n",
    "print(output.T)\n",
    "\n",
    "y = np.zeros((10, 1))\n",
    "y[5, 0] = 1.\n",
    "print(\"LOG\", np.sum(np.log(output.T)*y.T))\n",
    "# PART THREE _ FINITE DIFFS\n",
    "cost = cost_function(y, output)\n",
    "print(\"Cost\", cost)\n",
    "\n",
    "\n",
    "h = 0.001\n",
    "for i in range(5):\n",
    "    place = 215+i\n",
    "    weights2 = weights.copy()\n",
    "    #print(weights[place, 5])\n",
    "    weights2[place, 5] += h\n",
    "    #print(weights2[place, 5])\n",
    "    output2 = part2(x, weights2, weights_bias)\n",
    "    output2 = output2.reshape(10,1)\n",
    "\n",
    "    #print(\"LOG2\", np.sum(np.log(output2)*y.T))\n",
    "    cost2 = cost_function(y, output2)\n",
    "    #print(\"\\n\")\n",
    "    #print(output2)\n",
    "    #print(output.T==output2)\n",
    "    #print(\"Cost2\", cost2)\n",
    "    #print(cost, cost2)\n",
    "    print(\"Finite Diff\", (cost2 - cost) / h)\n",
    "    real_diff = part3(x, y, output)\n",
    "    #print(real_diff.shape)\n",
    "    #print(np.where(np.isclose(real_diff, (cost2-cost)/h, atol=1e-02)==True))\n",
    "    print(\"Real Diff\", real_diff[place+1, 5])\n",
    "    #print(np.where((real_diff > 1.)))\n",
    "    #print(real_diff[np.where(real_diff!=0)])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CSC401]",
   "language": "python",
   "name": "conda-env-CSC401-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
